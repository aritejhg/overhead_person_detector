{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Door detector v1.ipynb",
      "provenance": [],
      "mount_file_id": "12PpiucNwojU7hGNlRH7hkPw9FbCTw809",
      "authorship_tag": "ABX9TyM0KC7YKdRQh+c+Qriqv5yM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aritejhg/tinyyolov4_person_detector/blob/main/Door_detector_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#collins people at door detector\n",
        "\n",
        "Objectives:\n",
        "1. Convert Sunmi and Top View Multiple Person dataset to YOLO format (done)\n",
        "2. Implement histogram equalisation\n",
        "3. Get baseline from KDE background subtraction + Historgram\n",
        "4. Train TinyYOLOv4 model and check performance. Implement with DIoU + Multi-Scale\n",
        "5. If TinyYOLOV4 is better, convert it to tf-lite\n",
        "Result required: Just a indication if people are present in the area. To be passed to other code for talking to MiR\n",
        "6. compare against efficientdet-lite?\n",
        "\n",
        "Max resolution of feed?\n",
        "\n",
        "Return the highest confidence level of human detection?\n",
        "\n",
        "Need to return yes/no for occupancy, 90-95% accurate\n"
      ],
      "metadata": {
        "id": "ryFqzah2eiye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jekXvQdhn-_Q",
        "outputId": "a83d3255-325e-4fa7-d59f-155bb9e4dfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "1. [Training tinyYOLOv4](https://colab.research.google.com/drive/1hQO4nOoD6RDxdbz3C1YSiifTsyZjZpYm?usp=sharing)\n",
        "2. [Top View Multi Person labelled images zip](https://drive.google.com/drive/folders/1dc1QrDvZPWXbUfzEQE5EPIAz2CPCVI38)\n",
        "3. [Sunmi dataset](https://github.com/Sunmi-AI-Lab/head-detection-and-tracking/tree/master/datasets) \n",
        "4. [DIoU](https://arxiv.org/abs/1911.08287)\n",
        "5. [Multi-Scale tinyYOLOv4 Research paper](https://link.springer.com/chapter/10.1007/978-3-030-85383-9_1)\n",
        "6. [convert to tflite](https://github.com/DoranLyong/yolov4-tiny-tflite-for-person-detection)"
      ],
      "metadata": {
        "id": "D-e2kDHPgXt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports \n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import fnmatch"
      ],
      "metadata": {
        "id": "BNNfISdI09pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "5okoL7aCktwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download datasets"
      ],
      "metadata": {
        "id": "INTue4ZtMaM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "!pip install gdown\n",
        "import gdown"
      ],
      "metadata": {
        "id": "LMLsUUTt1JL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sunmi dataset"
      ],
      "metadata": {
        "id": "O6QqCM1rkyck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install subversion"
      ],
      "metadata": {
        "id": "_dSJbGfegXfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY8VHWHFbb7m"
      },
      "outputs": [],
      "source": [
        "!svn checkout https://github.com/Sunmi-AI-Lab/head-detection-and-tracking/trunk/datasets/in-office /content/Sunmi/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top View \n"
      ],
      "metadata": {
        "id": "19qO_lftlfy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/TVMP\")"
      ],
      "metadata": {
        "id": "LsZ0BF-unG-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://drive.google.com/drive/folders/1dc1QrDvZPWXbUfzEQE5EPIAz2CPCVI38?usp=sharing\n",
        "!gdown --folder https://drive.google.com/drive/folders/1dc1QrDvZPWXbUfzEQE5EPIAz2CPCVI38?usp=sharing /content/TVMP/"
      ],
      "metadata": {
        "id": "uBArrG_JlsOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/TVMP/labeled_images/test.zip"
      ],
      "metadata": {
        "id": "SRr5BZYEqbqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/TVMP/labeled_images/train.zip "
      ],
      "metadata": {
        "id": "Lb2gXkU8qpZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Backup downloaded datasets to drive"
      ],
      "metadata": {
        "id": "HjCi6ehTwPhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copytree(\"/content/Sunmi\",\"/content/drive/MyDrive/dataset/\")"
      ],
      "metadata": {
        "id": "Whtnl63uvth8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copytree(\"/content/TVMP\",\"/content/drive/MyDrive/dataset/TVMP\")"
      ],
      "metadata": {
        "id": "pEXrYfg-wb4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting datasets to YOLO format\n"
      ],
      "metadata": {
        "id": "jv3zkJlA1R4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While TVMP appears to be in YOLO format, Sunmi is in VOC XML with xmin ymin xmax ymax.\n",
        "\n",
        "YOLO format is x_center, y_center, width, height. \n",
        "\n",
        "Conversion is required for sunmi using script below\n",
        "\n",
        "\n",
        "Some files (hide annotations under Sunmi) have a different xml format, where they use xmin xmax ymin ymax instead of xmin ymin xmax ymax. These weird files also do not have width and height data at the start, so we use that to separate out the processing so that info is passed in the correct order to xml_to_yolo_bbox function.\n"
      ],
      "metadata": {
        "id": "Heq7X0t7VA3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspired from https://towardsdatascience.com/convert-pascal-voc-xml-to-yolo-for-object-detection-f969811ccba5\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "classes = [\"head\"]\n",
        "input_dir = \"/content/drive/MyDrive/dataset/in-office/annotations/\"\n",
        "output_dir = \"/content/drive/MyDrive/dataset/in-office/labels/\"\n",
        "image_dir = \"/content/drive/MyDrive/dataset/in-office/images/\"\n",
        "\n",
        "def xml_to_yolo_bbox(bbox, w, h):\n",
        "    # xmin, ymin, xmax, ymax\n",
        "    x_center = ((bbox[2] + bbox[0]) / 2) / w\n",
        "    y_center = ((bbox[3] + bbox[1]) / 2) / h\n",
        "    width = (bbox[2] - bbox[0]) / w\n",
        "    height = (bbox[3] - bbox[1]) / h\n",
        "    return [x_center, y_center, width, height]\n",
        "\n",
        "files = glob.glob(os.path.join(input_dir, '*.xml'))\n",
        "for i,fil in enumerate(files):\n",
        "    #print (fil)\n",
        "    basename = os.path.basename(fil)\n",
        "    filename = os.path.splitext(basename)[0]\n",
        "    if not os.path.exists(os.path.join(image_dir, f\"{filename}.jpg\")):\n",
        "        print(f\"{filename} image does not exist!\")\n",
        "        continue\n",
        "    \n",
        "    result = []\n",
        "    os.makedirs(\"/content/drive/MyDrive/dataset/in-office/labels\", exist_ok = True)\n",
        "    # parse the content of the xml file\n",
        "    tree = ET.parse(fil)\n",
        "    root = tree.getroot()\n",
        "    try: \n",
        "      width = int(root.find(\"size\").find(\"width\").text)\n",
        "      height = int(root.find(\"size\").find(\"height\").text)\n",
        "      for obj in root.findall('object'):\n",
        "        # since we are using only 1 class, this isnt necessary\n",
        "        # label = obj.find(\"name\").text\n",
        "        # # check for new classes and append to list\n",
        "        # if label not in classes:\n",
        "        #     classes.append(label)\n",
        "        # index = classes.index(label)\n",
        "        pil_bbox = [int(x.text) for x in obj.find(\"bndbox\")]\n",
        "        yolo_bbox = xml_to_yolo_bbox(pil_bbox, width, height)\n",
        "        \n",
        "    except: \n",
        "      width, height = 800, 800\n",
        "      print(fil)\n",
        "      for obj in root.findall('object'):\n",
        "        # since we are using only 1 class, this isnt necessary\n",
        "        # label = obj.find(\"name\").text\n",
        "        # # check for new classes and append to list\n",
        "        # if label not in classes:\n",
        "        #     classes.append(label)\n",
        "        # index = classes.index(label)\n",
        "        pil_bbox = [int(x.text) for x in obj.find(\"bndbox\")]\n",
        "        final_box = [pil_bbox[0],pil_bbox[2],pil_bbox[1],pil_bbox[3]] #done coz these files have a xmin xmax ymin ymax format\n",
        "        yolo_bbox = xml_to_yolo_bbox(final_box, width, height)\n",
        "\n",
        "    # convert data to string\n",
        "    bbox_string = \" \".join([str(x) for x in yolo_bbox])\n",
        "    result.append(f\"0 {bbox_string}\")\n",
        "    if result:\n",
        "        # generate a YOLO format text file for each xml file\n",
        "        with open(os.path.join(output_dir, f\"{filename}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n\".join(result))\n",
        "        print (f\"{i+1}/{len(files)} done\")\n",
        "# the ones with no height width data are giving a negative bbox value when converted to yolo, needs to be checked"
      ],
      "metadata": {
        "id": "9dqjHBIGu4Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Combine & create train/val/test folders"
      ],
      "metadata": {
        "id": "cao08vgIMV8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "80-10-10 split"
      ],
      "metadata": {
        "id": "85JnUjKPM4fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy over both datasets to a new folder\n",
        "for folder in [\"train\",'test', 'val', 'raw']:\n",
        "  os.makedirs(\"/content/dataset/\"+folder, exist_ok=True)\n",
        "\n",
        "for files in os.listdir(\"/content/drive/MyDrive/dataset/in-office/images\"):\n",
        "  print(files)\n",
        "  shutil.copy(\"/content/drive/MyDrive/dataset/in-office/images/\"+files, \"/content/dataset/raw/\")\n",
        "!cp -r /content/drive/MyDrive/dataset/TVMP/labeled_images/train/. /content/dataset/raw # j another method of copying\n",
        "!cp -r /content/drive/MyDrive/dataset/TVMP/labeled_images/test/. /content/dataset/raw\n",
        "\n",
        "!rm -rf -d /content/dataset/raw/*.txt\n",
        "# coz TVMP has images and txt tgt so we can just delete first, divide up the images only into train test val, then load up annotations"
      ],
      "metadata": {
        "id": "PW7Qo1DuhCVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check to confirm total number of images\n",
        "print(len(fnmatch.filter(os.listdir(\"/content/dataset/raw\"), '*.jpg')))\n",
        "print (len(fnmatch.filter(os.listdir(\"/content/drive/MyDrive/dataset/TVMP/labeled_images/test/\"), '*.jpg'))+len(fnmatch.filter(os.listdir(\"/content/drive/MyDrive/dataset/TVMP/labeled_images/train/\"), '*.jpg'))+len(fnmatch.filter(os.listdir(\"/content/drive/MyDrive/dataset/in-office/images\"), '*.jpg')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcB4er361V0u",
        "outputId": "63deff36-ce4e-4c37-e7da-1bd5aef1e480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6075\n",
            "6075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(100) #seed so that rerunning will not change data in the folders\n",
        "root_path = \"/content/dataset/raw/\"\n",
        "# create list of images\n",
        "list_of_images = list(set(fnmatch.filter(os.listdir(\"/content/dataset/raw\"), '*.jpg')))\n",
        "total_images = len(list_of_images)\n",
        "# print(list_of_images)\n",
        "# print(total_images)\n",
        "# choose images for training, testing, and validation sets\n",
        "train_images = []\n",
        "val_images = []\n",
        "test_images = []\n",
        "for i in range(int(total_images*0.8)):\n",
        "   train_choice = random.choice(list_of_images)\n",
        "   train_images.append(train_choice)\n",
        "   list_of_images.remove(train_choice)\n",
        "for i in range(int(total_images*0.1)):\n",
        "   val_choice = random.choice(list_of_images)\n",
        "   val_images.append(val_choice)\n",
        "   list_of_images.remove(val_choice)\n",
        "test_images = list_of_images #since only 10% test data is left\n",
        "\n",
        "print(len(train_images),len(val_images), len(test_images))\n",
        "# print(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc-AEhc_qjTp",
        "outputId": "4549d1d4-7c56-443d-ad02-ceae20cb1ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4860 607 608\n",
            "['cam_5_2_and_helf_mins_00000269.jpg', 'jacket_1208.jpg', 'cam_1_2_and_helf_mins_00000091.jpg', 'cam6_1hour_00000124.jpg', 'cam_3_2_and_helf_mins_00000224.jpg', 'cam_6_2_and_helf_mins_00000251.jpg', 'cam1_1hour_00000089.jpg', 'cam_6_train_00000075.jpg', 'cam_2_trimmed_00000120.jpg', 'cam_1_2_and_helf_mins_00000113.jpg', 'cam_3_00000050.jpg', 'hide_0201.jpg', 'cam_6_train_00000100.jpg', 'cam_3_2_and_helf_mins_00000111.jpg', 'hide_0590.jpg', 'cam_3_trimmed_00000066.jpg', 'hide_0122.jpg', 'hide_0132.jpg', 'hide_0174.jpg', 'cam3_1hour_00000122.jpg', 'cam_2_00000045.jpg', 'cam_2_00000028.jpg', 'close_0359.jpg', 'close_0857.jpg', 'lightoff_0752.jpg', 'cam_1_00000094.jpg', 'hide_0107.jpg', 'cam_5_train_00000055.jpg', 'cam_5_train_00000095.jpg', 'cam_2_00000005.jpg', 'cam_1_2_and_helf_mins_00000085.jpg', 'cam1_1hour_00000091.jpg', 'hide_0099.jpg', 'cam_6_2_and_helf_mins_00000038.jpg', 'hide_0364.jpg', 'cam_2_2_and_helf_mins_00000088.jpg', 'cam_3_trimmed_00000017.jpg', 'cam1_1hour_00000022.jpg', 'squat_0008.jpg', 'cam_6_train_00000067.jpg', 'cam_6_2_and_helf_mins_00000011.jpg', 'cam6_1hour_00000126.jpg', 'cam2_1hour_00000050.jpg', 'cam_5_trimmed_00000060.jpg', 'hide_0495.jpg', 'close_0598.jpg', 'cam5_1hour_00000060.jpg', 'cam1_1hour_00000098.jpg', 'cam_1_2_and_helf_mins_00000255.jpg', 'cam_3_2_and_helf_mins_00000267.jpg', 'cam_3_test_00000022.jpg', 'cam_6_2_and_helf_mins_00000079.jpg', 'cam_6_2_and_helf_mins_00000200.jpg', 'cam_1_2_and_helf_mins_00000254.jpg', 'hide_0032.jpg', 'hide_0204.jpg', 'cam_2_2_and_helf_mins_00000338.jpg', 'cam_6_2_and_helf_mins_00000204.jpg', 'cam3_1hour_00000039.jpg', 'cam_1_2_and_helf_mins_00000200.jpg', 'cam_1_2_and_helf_mins_00000021.jpg', 'cam_6_2_and_helf_mins_00000248.jpg', 'cam_6_2_and_helf_mins_00000173.jpg', 'cam_2_2_and_helf_mins_00000233.jpg', 'cam_5_2_and_helf_mins_00000206.jpg', 'cam_6_2_and_helf_mins_00000135.jpg', 'cam_3_trimmed_00000036.jpg', 'hide_0755.jpg', 'cam_6_2_and_helf_mins_00000241.jpg', 'cam_3_2_and_helf_mins_00000064.jpg', 'cam_6_trimmed_00000088.jpg', 'cam_6_2_and_helf_mins_00000107.jpg', 'cam_5_2_and_helf_mins_00000263.jpg', 'cam_2_00000017.jpg', 'squat_0372.jpg', 'cam_6_2_and_helf_mins_00000155.jpg', 'jacket_0694.jpg', 'cam_6_train_00000042.jpg', 'cam_6_2_and_helf_mins_00000299.jpg', 'cam_3_00000257.jpg', 'cam_3_00000126.jpg', 'hide_0566.jpg', 'cam2_1hour_00000033.jpg', 'cam_5_test_00000003.jpg', 'close_0675.jpg', 'cam_5_2_and_helf_mins_00000163.jpg', 'cam_2_2_and_helf_mins_00000050.jpg', 'cam_3_trimmed_00000002.jpg', 'cam_5_train_00000096.jpg', 'cam_6_train_00000076.jpg', 'hide_0424.jpg', 'lightoff_0627.jpg', 'cam_5_2_and_helf_mins_00000130.jpg', 'cam_5_2_and_helf_mins_00000143.jpg', 'cam_2_2_and_helf_mins_00000009.jpg', 'cam_6_2_and_helf_mins_00000087.jpg', 'cam_3_2_and_helf_mins_00000292.jpg', 'cam3_1hour_00000007.jpg', 'cam_5_2_and_helf_mins_00000312.jpg', 'cam_2_00000238.jpg', 'cam_2_2_and_helf_mins_00000137.jpg', 'cam_3_2_and_helf_mins_00000032.jpg', 'cam_2_00000302.jpg', 'cam_2_trimmed_00000126.jpg', 'hat_1098.jpg', 'cam_2_2_and_helf_mins_00000049.jpg', 'cam_3_2_and_helf_mins_00000167.jpg', 'cam5_1hour_00000042.jpg', 'cam_2_00000310.jpg', 'squat_0587.jpg', 'cam_1_00000039.jpg', 'cam_1_00000151.jpg', 'cam_3_2_and_helf_mins_00000118.jpg', 'jacket_0181.jpg', 'cam3_1hour_00000006.jpg', 'cam5_1hour_00000000.jpg', 'cam_5_2_and_helf_mins_00000274.jpg', 'cam_6_test_00000018.jpg', 'hat_0438.jpg', 'cam_1_trimmed_00000074.jpg', 'squat_0073.jpg', 'cam_2_2_and_helf_mins_00000039.jpg', 'cam_5_2_and_helf_mins_00000073.jpg', 'cam_2_00000134.jpg', 'hide_0195.jpg', 'hat_2683.jpg', 'close_0719.jpg', 'cam_3_00000104.jpg', 'cam_6_test_00000028.jpg', 'cam_1_trimmed_00000087.jpg', 'hide_0382.jpg', 'hide_0187.jpg', 'cam1_1hour_00000060.jpg', 'cam_5_train_00000088.jpg', 'hide_0079.jpg', 'hide_0353.jpg', 'hat_1195.jpg', 'hide_0224.jpg', 'cam_1_2_and_helf_mins_00000290.jpg', 'cam_5_2_and_helf_mins_00000025.jpg', 'cam_5_2_and_helf_mins_00000330.jpg', 'cam_3_trimmed_00000003.jpg', 'hide_0027.jpg', 'jacket_0084.jpg', 'cam_3_00000124.jpg', 'cam5_1hour_00000036.jpg', 'hide_0522.jpg', 'cam_5_2_and_helf_mins_00000054.jpg', 'cam_2_2_and_helf_mins_00000168.jpg', 'cam_2_00000082.jpg', 'close_0406.jpg', 'cam_3_trimmed_00000018.jpg', 'hide_0503.jpg', 'cam_5_trimmed_00000090.jpg', 'hide_0511.jpg', 'cam_6_trimmed_00000112.jpg', 'cam1_1hour_00000051.jpg', 'cam_5_trimmed_00000050.jpg', 'cam_5_2_and_helf_mins_00000345.jpg', 'cam_6_2_and_helf_mins_00000103.jpg', 'cam_1_2_and_helf_mins_00000217.jpg', 'cam_5_train_00000116.jpg', 'squat_0488.jpg', 'cam_5_2_and_helf_mins_00000313.jpg', 'cam_3_2_and_helf_mins_00000087.jpg', 'squat_0612.jpg', 'cam_1_2_and_helf_mins_00000156.jpg', 'cam_2_2_and_helf_mins_00000140.jpg', 'hide_0058.jpg', 'cam_2_2_and_helf_mins_00000257.jpg', 'cam_5_2_and_helf_mins_00000045.jpg', 'jacket_0160.jpg', 'cam_2_00000148.jpg', 'cam_2_test_00000012.jpg', 'cam_2_00000056.jpg', 'cam_1_00000225.jpg', 'cam6_1hour_00000095.jpg', 'cam_5_2_and_helf_mins_00000333.jpg', 'cam_2_2_and_helf_mins_00000301.jpg', 'hide_0559.jpg', 'cam_5_trimmed_00000097.jpg', 'cam_2_2_and_helf_mins_00000019.jpg', 'cam_6_2_and_helf_mins_00000232.jpg', 'cam_6_trimmed_00000003.jpg', 'cam_3_trimmed_00000115.jpg', 'cam_1_2_and_helf_mins_00000249.jpg', 'cam_5_2_and_helf_mins_00000196.jpg', 'cam_5_2_and_helf_mins_00000256.jpg', 'cam_1_2_and_helf_mins_00000090.jpg', 'cam5_1hour_00000093.jpg', 'cam_2_00000219.jpg', 'hide_0158.jpg', 'cam_3_00000197.jpg', 'squat_0780.jpg', 'cam_3_2_and_helf_mins_00000172.jpg', 'lightoff_0794.jpg', 'cam6_1hour_00000133.jpg', 'cam_5_trimmed_00000114.jpg', 'cam_2_00000273.jpg', 'cam_5_2_and_helf_mins_00000262.jpg', 'hide_0304.jpg', 'cam_3_2_and_helf_mins_00000158.jpg', 'cam_6_2_and_helf_mins_00000318.jpg', 'cam_1_2_and_helf_mins_00000191.jpg', 'hide_0393.jpg', 'hide_0320.jpg', 'cam_5_2_and_helf_mins_00000213.jpg', 'close_0607.jpg', 'squat_0025.jpg', 'cam_3_2_and_helf_mins_00000347.jpg', 'cam_2_trimmed_00000036.jpg', 'hide_0463.jpg', 'cam_2_2_and_helf_mins_00000308.jpg', 'cam_6_trimmed_00000070.jpg', 'jacket_0704.jpg', 'jacket_0838.jpg', 'cam_5_2_and_helf_mins_00000058.jpg', 'cam5_1hour_00000028.jpg', 'cam_3_00000261.jpg', 'hide_0247.jpg', 'cam5_1hour_00000106.jpg', 'cam_5_2_and_helf_mins_00000072.jpg', 'cam_3_2_and_helf_mins_00000241.jpg', 'cam3_1hour_00000013.jpg', 'cam_2_00000063.jpg', 'squat_0182.jpg', 'cam_2_00000107.jpg', 'cam_2_2_and_helf_mins_00000266.jpg', 'cam_1_2_and_helf_mins_00000291.jpg', 'hide_0225.jpg', 'cam_6_train_00000056.jpg', 'cam6_1hour_00000023.jpg', 'cam_2_00000195.jpg', 'cam_2_trimmed_00000085.jpg', 'cam_3_trimmed_00000037.jpg', 'cam_3_trimmed_00000043.jpg', 'cam_3_2_and_helf_mins_00000336.jpg', 'cam_2_00000180.jpg', 'cam_2_2_and_helf_mins_00000311.jpg', 'lightoff_0405.jpg', 'cam_3_2_and_helf_mins_00000330.jpg', 'hide_0466.jpg', 'cam_3_2_and_helf_mins_00000298.jpg', 'cam_2_2_and_helf_mins_00000136.jpg', 'cam_5_2_and_helf_mins_00000200.jpg', 'cam3_1hour_00000057.jpg', 'hide_0098.jpg', 'cam_5_2_and_helf_mins_00000068.jpg', 'squat_0624.jpg', 'hide_0419.jpg', 'cam_5_2_and_helf_mins_00000153.jpg', 'cam_3_2_and_helf_mins_00000030.jpg', 'close_0023.jpg', 'cam_3_00000131.jpg', 'cam_6_2_and_helf_mins_00000245.jpg', 'lightoff_0320.jpg', 'squat_0147.jpg', 'cam6_1hour_00000080.jpg', 'cam_5_2_and_helf_mins_00000067.jpg', 'cam_5_2_and_helf_mins_00000216.jpg', 'cam6_1hour_00000094.jpg', 'cam_1_2_and_helf_mins_00000247.jpg', 'cam_1_2_and_helf_mins_00000330.jpg', 'cam_6_train_00000043.jpg', 'hat_1643.jpg', 'squat_0782.jpg', 'cam_6_train_00000084.jpg', 'cam_1_00000221.jpg', 'cam_6_2_and_helf_mins_00000077.jpg', 'cam_3_00000025.jpg', 'cam_6_train_00000174.jpg', 'cam_5_trimmed_00000044.jpg', 'squat_0122.jpg', 'jacket_0086.jpg', 'lightoff_0680.jpg', 'cam_1_00000081.jpg', 'cam_3_trimmed_00000033.jpg', 'cam2_1hour_00000047.jpg', 'hide_0343.jpg', 'cam_1_00000046.jpg', 'cam_6_train_00000057.jpg', 'cam3_1hour_00000063.jpg', 'cam_2_trimmed_00000013.jpg', 'cam_2_00000268.jpg', 'cam_1_2_and_helf_mins_00000093.jpg', 'cam_5_2_and_helf_mins_00000225.jpg', 'hide_0707.jpg', 'lightoff_0053.jpg', 'cam_5_2_and_helf_mins_00000074.jpg', 'cam_6_2_and_helf_mins_00000202.jpg', 'hide_0121.jpg', 'cam6_1hour_00000067.jpg', 'cam_3_00000151.jpg', 'close_0499.jpg', 'cam_2_00000228.jpg', 'hide_0680.jpg', 'lightoff_0382.jpg', 'cam5_1hour_00000128.jpg', 'cam_6_test_00000015.jpg', 'hat_1819.jpg', 'lightoff_0460.jpg', 'cam_1_2_and_helf_mins_00000001.jpg', 'lightoff_0434.jpg', 'cam_1_2_and_helf_mins_00000056.jpg', 'cam_6_train_00000162.jpg', 'squat_0479.jpg', 'cam3_1hour_00000022.jpg', 'cam_5_2_and_helf_mins_00000001.jpg', 'hat_0927.jpg', 'cam_2_2_and_helf_mins_00000342.jpg', 'cam_2_00000113.jpg', 'hat_0457.jpg', 'hide_0171.jpg', 'cam_3_00000081.jpg', 'hide_0494.jpg', 'jacket_0992.jpg', 'cam_6_trimmed_00000062.jpg', 'cam_1_trimmed_00000100.jpg', 'cam_5_2_and_helf_mins_00000004.jpg', 'cam_5_test_00000022.jpg', 'close_0058.jpg', 'cam_5_2_and_helf_mins_00000178.jpg', 'cam_2_2_and_helf_mins_00000282.jpg', 'close_0562.jpg', 'cam_1_2_and_helf_mins_00000047.jpg', 'cam_2_2_and_helf_mins_00000103.jpg', 'cam_3_2_and_helf_mins_00000074.jpg', 'cam_6_2_and_helf_mins_00000125.jpg', 'cam_5_trimmed_00000003.jpg', 'cam6_1hour_00000031.jpg', 'hide_0431.jpg', 'close_0829.jpg', 'close_0538.jpg', 'cam_2_00000090.jpg', 'cam_5_2_and_helf_mins_00000270.jpg', 'cam_2_00000006.jpg', 'cam_1_00000199.jpg', 'cam2_1hour_00000045.jpg', 'hide_0668.jpg', 'hide_0468.jpg', 'jacket_0770.jpg', 'squat_0564.jpg', 'cam6_1hour_00000102.jpg', 'cam_1_2_and_helf_mins_00000189.jpg', 'cam_2_00000231.jpg', 'hat_2331.jpg', 'cam6_1hour_00000020.jpg', 'cam_1_2_and_helf_mins_00000087.jpg', 'cam_6_2_and_helf_mins_00000291.jpg', 'cam_6_2_and_helf_mins_00000035.jpg', 'cam_3_00000134.jpg', 'cam_1_trimmed_00000070.jpg', 'cam_3_2_and_helf_mins_00000161.jpg', 'cam_6_2_and_helf_mins_00000089.jpg', 'cam_1_2_and_helf_mins_00000092.jpg', 'cam_5_trimmed_00000015.jpg', 'cam_6_2_and_helf_mins_00000292.jpg', 'hide_0647.jpg', 'lightoff_0196.jpg', 'lightoff_0432.jpg', 'lightoff_0204.jpg', 'hat_0022.jpg', 'cam1_1hour_00000025.jpg', 'cam_2_2_and_helf_mins_00000182.jpg', 'cam_6_2_and_helf_mins_00000005.jpg', 'hide_0355.jpg', 'cam_2_00000179.jpg', 'cam_3_trimmed_00000130.jpg', 'cam_2_00000226.jpg', 'cam_6_2_and_helf_mins_00000118.jpg', 'cam_5_2_and_helf_mins_00000003.jpg', 'cam_3_00000018.jpg', 'cam_1_00000126.jpg', 'jacket_0857.jpg', 'cam_2_00000173.jpg', 'cam_3_2_and_helf_mins_00000287.jpg', 'hide_0190.jpg', 'hide_0788.jpg', 'hide_0432.jpg', 'cam6_1hour_00000057.jpg', 'cam_1_trimmed_00000029.jpg', 'cam_2_2_and_helf_mins_00000089.jpg', 'cam_3_2_and_helf_mins_00000344.jpg', 'cam_1_2_and_helf_mins_00000103.jpg', 'cam_6_train_00000036.jpg', 'cam_1_00000120.jpg', 'close_0088.jpg', 'cam_1_2_and_helf_mins_00000283.jpg', 'cam_3_00000046.jpg', 'hide_0470.jpg', 'cam_6_test_00000011.jpg', 'cam6_1hour_00000003.jpg', 'cam_3_2_and_helf_mins_00000232.jpg', 'cam_2_00000141.jpg', 'cam_6_2_and_helf_mins_00000027.jpg', 'cam_6_trimmed_00000105.jpg', 'cam_6_train_00000135.jpg', 'cam3_1hour_00000015.jpg', 'hide_0245.jpg', 'close_0456.jpg', 'hide_0621.jpg', 'hide_0506.jpg', 'cam_5_2_and_helf_mins_00000137.jpg', 'cam_5_train_00000112.jpg', 'cam_1_2_and_helf_mins_00000025.jpg', 'cam_6_train_00000009.jpg', 'cam_1_trimmed_00000125.jpg', 'cam_1_00000154.jpg', 'cam_2_2_and_helf_mins_00000031.jpg', 'cam_1_00000196.jpg', 'cam_3_00000252.jpg', 'cam_3_2_and_helf_mins_00000299.jpg', 'cam_2_trimmed_00000078.jpg', 'cam6_1hour_00000027.jpg', 'jacket_1022.jpg', 'cam_6_2_and_helf_mins_00000332.jpg', 'cam_2_2_and_helf_mins_00000015.jpg', 'cam_3_trimmed_00000022.jpg', 'hide_0753.jpg', 'cam_1_2_and_helf_mins_00000331.jpg', 'cam1_1hour_00000079.jpg', 'cam5_1hour_00000097.jpg', 'cam_5_train_00000127.jpg', 'cam_5_trimmed_00000056.jpg', 'squat_0191.jpg', 'cam_3_00000244.jpg', 'cam_2_trimmed_00000042.jpg', 'cam_3_2_and_helf_mins_00000110.jpg', 'cam_1_00000001.jpg', 'hide_0054.jpg', 'cam_6_2_and_helf_mins_00000037.jpg', 'cam_2_00000100.jpg', 'cam6_1hour_00000070.jpg', 'cam_1_2_and_helf_mins_00000234.jpg', 'cam_1_00000023.jpg', 'hide_0100.jpg', 'cam_1_2_and_helf_mins_00000032.jpg', 'cam_1_2_and_helf_mins_00000171.jpg', 'cam_6_train_00000124.jpg', 'close_0183.jpg', 'cam2_1hour_00000002.jpg', 'cam_3_00000122.jpg', 'squat_0728.jpg', 'hide_0483.jpg', 'cam5_1hour_00000074.jpg', 'cam_5_test_00000029.jpg', 'cam_1_2_and_helf_mins_00000299.jpg', 'cam_3_00000243.jpg', 'hide_0805.jpg', 'cam5_1hour_00000067.jpg', 'cam_1_2_and_helf_mins_00000028.jpg', 'cam_1_00000028.jpg', 'cam_3_2_and_helf_mins_00000208.jpg', 'cam_6_2_and_helf_mins_00000322.jpg', 'cam2_1hour_00000087.jpg', 'close_0118.jpg', 'cam_3_00000048.jpg', 'cam_1_00000084.jpg', 'close_0287.jpg', 'hide_0526.jpg', 'cam2_1hour_00000132.jpg', 'cam_1_00000136.jpg', 'cam_3_00000116.jpg', 'cam_5_2_and_helf_mins_00000099.jpg', 'cam_3_2_and_helf_mins_00000198.jpg', 'hide_0008.jpg', 'cam_5_test_00000010.jpg', 'cam_3_2_and_helf_mins_00000311.jpg', 'close_0973.jpg', 'hide_0458.jpg', 'hide_0613.jpg', 'hat_1561.jpg', 'cam_2_trimmed_00000129.jpg', 'hide_0610.jpg', 'cam_3_00000165.jpg', 'cam6_1hour_00000032.jpg', 'cam_1_2_and_helf_mins_00000172.jpg', 'cam_5_2_and_helf_mins_00000223.jpg', 'cam_6_trimmed_00000127.jpg', 'cam_2_2_and_helf_mins_00000271.jpg', 'hide_0050.jpg', 'close_1016.jpg', 'lightoff_0834.jpg', 'cam_2_2_and_helf_mins_00000017.jpg', 'cam_3_2_and_helf_mins_00000082.jpg', 'hide_0442.jpg', 'cam_6_2_and_helf_mins_00000105.jpg', 'cam_3_2_and_helf_mins_00000026.jpg', 'close_0489.jpg', 'cam_2_2_and_helf_mins_00000275.jpg', 'cam_5_trimmed_00000000.jpg', 'cam_2_00000253.jpg', 'cam6_1hour_00000045.jpg', 'squat_0269.jpg', 'cam_5_trimmed_00000098.jpg', 'cam_6_2_and_helf_mins_00000032.jpg', 'cam_6_2_and_helf_mins_00000205.jpg', 'cam_6_2_and_helf_mins_00000239.jpg', 'cam_1_trimmed_00000131.jpg', 'cam6_1hour_00000001.jpg', 'close_0949.jpg', 'cam1_1hour_00000046.jpg', 'cam_6_2_and_helf_mins_00000098.jpg', 'hide_0071.jpg', 'cam3_1hour_00000062.jpg', 'cam_6_2_and_helf_mins_00000147.jpg', 'cam_2_trimmed_00000104.jpg', 'cam_6_2_and_helf_mins_00000326.jpg', 'cam_6_2_and_helf_mins_00000025.jpg', 'cam_6_test_00000002.jpg', 'cam_2_2_and_helf_mins_00000083.jpg', 'cam_6_train_00000117.jpg', 'cam_1_2_and_helf_mins_00000262.jpg', 'cam_5_trimmed_00000094.jpg', 'cam_1_trimmed_00000077.jpg', 'hide_0456.jpg', 'close_0411.jpg', 'cam5_1hour_00000012.jpg', 'squat_0143.jpg', 'cam3_1hour_00000084.jpg', 'cam_3_2_and_helf_mins_00000157.jpg', 'cam_6_trimmed_00000028.jpg', 'cam_3_00000136.jpg', 'cam5_1hour_00000089.jpg', 'cam_3_2_and_helf_mins_00000035.jpg', 'cam_3_2_and_helf_mins_00000116.jpg', 'cam_3_2_and_helf_mins_00000303.jpg', 'hide_0070.jpg', 'hide_0758.jpg', 'cam_6_2_and_helf_mins_00000006.jpg', 'cam_1_2_and_helf_mins_00000038.jpg', 'cam_2_2_and_helf_mins_00000054.jpg', 'cam_6_2_and_helf_mins_00000242.jpg', 'cam_6_2_and_helf_mins_00000284.jpg', 'cam_6_2_and_helf_mins_00000134.jpg', 'cam_5_test_00000006.jpg', 'cam_1_00000248.jpg', 'cam_5_test_00000030.jpg', 'cam_1_2_and_helf_mins_00000088.jpg', 'cam_3_test_00000009.jpg', 'cam_6_train_00000113.jpg', 'cam_3_trimmed_00000044.jpg', 'cam6_1hour_00000114.jpg', 'cam_2_trimmed_00000000.jpg', 'cam_5_trimmed_00000095.jpg', 'cam_6_2_and_helf_mins_00000270.jpg', 'cam3_1hour_00000061.jpg', 'close_0660.jpg', 'cam_6_2_and_helf_mins_00000259.jpg', 'cam2_1hour_00000049.jpg', 'hide_0634.jpg', 'cam_2_00000023.jpg', 'hide_0380.jpg', 'cam6_1hour_00000030.jpg', 'close_0541.jpg', 'cam_6_train_00000108.jpg', 'cam5_1hour_00000084.jpg', 'cam_5_2_and_helf_mins_00000329.jpg', 'cam_1_trimmed_00000129.jpg', 'cam_5_2_and_helf_mins_00000081.jpg', 'close_0836.jpg', 'hat_1207.jpg', 'cam_3_test_00000025.jpg', 'lightoff_0738.jpg', 'hat_0454.jpg', 'hide_0501.jpg', 'hide_0648.jpg', 'hide_0006.jpg', 'cam_5_2_and_helf_mins_00000159.jpg', 'cam_6_trimmed_00000110.jpg', 'cam5_1hour_00000099.jpg', 'cam_6_2_and_helf_mins_00000210.jpg', 'cam_1_trimmed_00000009.jpg', 'cam5_1hour_00000121.jpg', 'cam_2_00000264.jpg', 'hide_0111.jpg', 'cam_3_trimmed_00000072.jpg', 'cam_3_2_and_helf_mins_00000223.jpg', 'cam_3_2_and_helf_mins_00000093.jpg', 'cam_3_2_and_helf_mins_00000260.jpg', 'cam_5_trimmed_00000031.jpg', 'cam_2_2_and_helf_mins_00000303.jpg', 'hide_0036.jpg', 'close_0062.jpg', 'hide_0540.jpg', 'hide_0409.jpg', 'cam_2_00000051.jpg', 'lightoff_0452.jpg', 'cam_3_2_and_helf_mins_00000322.jpg', 'cam_5_2_and_helf_mins_00000101.jpg', 'jacket_0421.jpg', 'cam_1_00000055.jpg', 'lightoff_0972.jpg', 'cam_2_2_and_helf_mins_00000220.jpg', 'hide_0126.jpg', 'hide_0193.jpg', 'cam_3_00000024.jpg', 'cam6_1hour_00000071.jpg', 'cam_5_2_and_helf_mins_00000029.jpg', 'hat_1613.jpg', 'hat_0854.jpg', 'lightoff_0110.jpg', 'cam_6_2_and_helf_mins_00000279.jpg', 'hat_1042.jpg', 'cam1_1hour_00000047.jpg', 'hide_0104.jpg', 'cam1_1hour_00000037.jpg', 'close_0636.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#copy images based on the lists created \n",
        "root_path = \"/content/dataset/\"\n",
        "\n",
        "for train_img in train_images:\n",
        "  shutil.copy(root_path + \"raw/\" + train_img, os.path.join(root_path, \"train/\"))\n",
        "for val_img in val_images:\n",
        "  shutil.copy(root_path + \"raw/\" + val_img, os.path.join(root_path, \"val/\"))  \n",
        "for test_img in test_images:\n",
        "  shutil.copy(root_path + \"raw/\" + test_img, os.path.join(root_path, \"test/\"))  "
      ],
      "metadata": {
        "id": "EP-vdqEDT7un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check, check numbers in each folder match up with print in cell earlier\n",
        "print(len(fnmatch.filter(os.listdir(\"/content/dataset/train\"), '*.jpg')))\n",
        "print(len(fnmatch.filter(os.listdir(\"/content/dataset/val\"), '*.jpg')))\n",
        "print(len(fnmatch.filter(os.listdir(\"/content/dataset/test\"), '*.jpg')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nws6B2FYUwIa",
        "outputId": "072692ea-c66a-4e1c-ba58-216f0cdb16a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4860\n",
            "607\n",
            "608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a raw_labels folder to find labels and copy into train/val/test folder. Inefficient overall but a 1-time run + easier to code \n",
        "os.makedirs(\"/content/dataset/raw_labels\", exist_ok=True)\n",
        "for files in  fnmatch.filter(os.listdir(\"/content/drive/MyDrive/dataset/in-office/labels\"), '*.txt'):\n",
        "  shutil.copy(\"/content/drive/MyDrive/dataset/in-office/labels/\"+ files, \"/content/dataset/raw_labels/\")\n",
        "for files in fnmatch.filter(os.listdir(\"/content/drive/MyDrive/dataset/TVMP/labeled_images/test/\"), '*.txt'):\n",
        "  shutil.copy(\"/content/drive/MyDrive/dataset/TVMP/labeled_images/test/\"+ files, \"/content/dataset/raw_labels/\")\n",
        "for files in fnmatch.filter(os.listdir(\"/content/drive/MyDrive/dataset/TVMP/labeled_images/train/\"), '*.txt'):\n",
        "  shutil.copy(\"/content/drive/MyDrive/dataset/TVMP/labeled_images/train/\"+ files, \"/content/dataset/raw_labels/\")\n"
      ],
      "metadata": {
        "id": "6TiroMl_VpCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check. total files in raw labels\n",
        "print(len(fnmatch.filter(os.listdir(\"/content/dataset/raw_labels\"), '*.txt')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSULbonDZMvb",
        "outputId": "436e5eb9-625c-4771-a9cb-470be00e3a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now to actl copy over labels\n",
        "root_path = \"/content/dataset/\"\n",
        "\n",
        "for train_img in train_images:\n",
        "  shutil.copy(root_path + \"raw_labels/\" + train_img.rstrip(\".jpg\") + \".txt\", os.path.join(root_path, \"train/\"))\n",
        "for val_img in val_images:\n",
        "  shutil.copy(root_path + \"raw_labels/\" + val_img.rstrip(\".jpg\") + \".txt\", os.path.join(root_path, \"val/\"))  \n",
        "for test_img in test_images:\n",
        "  shutil.copy(root_path + \"raw_labels/\" + test_img.rstrip(\".jpg\") + \".txt\", os.path.join(root_path, \"test/\"))  "
      ],
      "metadata": {
        "id": "J0qbqa0aaBfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check, check numbers in each folder match up with print in cell earlier\n",
        "print(len(fnmatch.filter(os.listdir(\"/content/dataset/train\"), '*.txt')))\n",
        "print(len(fnmatch.filter(os.listdir(\"/content/dataset/val\"), '*.txt')))\n",
        "print(len(fnmatch.filter(os.listdir(\"/content/dataset/test\"), '*.txt')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJvCP4aIb5JM",
        "outputId": "7b34f714-d8bd-4422-fb8b-d5d0c89f182c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4860\n",
            "607\n",
            "608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving final created dataset to gdrive\n",
        "!cp -r /content/dataset/train /content/drive/MyDrive/dataset/final_dataset\n",
        "!cp -r /content/dataset/val /content/drive/MyDrive/dataset/final_dataset\n",
        "!cp -r /content/dataset/test /content/drive/MyDrive/dataset/final_dataset"
      ],
      "metadata": {
        "id": "gzP7dNOKcks7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data-preprocessing"
      ],
      "metadata": {
        "id": "wwGIeXZb4rtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things needed:\n",
        "1. Create torch.dataset thingy\n",
        "2. resolution? currently j gon use 416*416\n",
        "3. Preprocesses to be done?\n",
        "4. Histogram equalization before feeding in the image?\n",
        "5. transfer learning?\n"
      ],
      "metadata": {
        "id": "iTp7qb2fgLbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import TensorDataset\n",
        "# from torch.utils.data import DataLoader\n",
        "# import torchvision\n",
        "# from torchvision import datasets, models, transforms\n",
        "# import time\n",
        "# import os\n",
        "# import random"
      ],
      "metadata": {
        "id": "WsSXkJuegILy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def data_loader(batch_size = 32, mode = \"train\", root_path = \"/content/\"):\n",
        "#   transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# #experiment with grayscale?\n",
        "#   if mode == 'train':\n",
        "#     dataset = torchvision.datasets.ImageFolder(root_path + \"train/\", transform=transform)\n",
        "#     dataloader = DataLoader(dataset, batch_size=batch_size, num_workers = 2, shuffle=True)\n",
        "#   if mode == 'val':\n",
        "#     dataset = torchvision.datasets.ImageFolder(root_path + \"val/\", transform=transform)\n",
        "#     dataloader = DataLoader(dataset, batch_size=batch_size, num_workers = 2, shuffle=True)\n",
        "#   if mode == 'test':\n",
        "#     dataset = torchvision.datasets.ImageFolder(root_path + \"test/\", transform=transform)     \n",
        "#     dataloader = DataLoader(dataset, batch_size=batch_size, num_workers = 2, shuffle=True)\n",
        "#   return dataloader"
      ],
      "metadata": {
        "id": "KNPOaJJCgIJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "metadata": {
        "id": "OA0Wktc6gIG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install libopencv-dev\n",
        "!make"
      ],
      "metadata": {
        "id": "XxcbYR-hmVH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/darknet/cfg/yolov4-tiny-custom.cfg /content/yolov4-tiny/"
      ],
      "metadata": {
        "id": "rRa91eX6gIEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change makefile to have GPU and OPENCV enabled\n",
        "# also set CUDNN, CUDNN_HALF and LIBSO to 1\n",
        "\n",
        "%cd /content/darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIzOZm4ElQE0",
        "outputId": "be2f3641-b045-4b61-d9f0-e2bfba9a4d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/darknet/data \n",
        "!find -maxdepth 1 -type f -exec rm -rf {} \\;"
      ],
      "metadata": {
        "id": "vWyoXpHtnE-L"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd .. \n",
        "!rm -rf cfg/ \n",
        "!mkdir cfg "
      ],
      "metadata": {
        "id": "1RmIE2AXnE6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo -e 'Humans' > data/obj.names\n",
        "!echo -e 'classes = 1\\ntrain  = /content/dataset/train.txt\\nvalid  = /content/dataset/valid.txt\\nnames = /content/darknet/data/obj.names\\nbackup = /content/darknet/backup' > data/obj.data"
      ],
      "metadata": {
        "id": "yOTGXWuosYFh"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/dataset/train.txt', 'w') as file_train:\n",
        "  for train_img in train_images:\n",
        "    file_train.write\n",
        "\n",
        "file_val = open('/content/dataset/val.txt', 'w')\n",
        "file_test = open('/content/dataset/test.txt', 'w')\n"
      ],
      "metadata": {
        "id": "RYnh0qXNuMuK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}